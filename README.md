# Smart Support - Intelligent Customer Support System

AI-powered customer inquiry classification and template retrieval system for VTB Belarus banking support.

## Overview

Smart Support is a two-module AI system that transforms customer support operations:

1. **Classification Module**: Automatically analyzes Russian banking inquiries and assigns them to product categories and subcategories (‚â•70% accuracy, <2s response time)
2. **Template Retrieval Module**: Finds and ranks relevant FAQ templates using semantic similarity (‚â•80% top-3 accuracy, <1s retrieval time)

Built for the Minsk Hackathon using Scibox LLM platform with Qwen2.5-72B-Instruct-AWQ (classification) and bge-m3 (embeddings).

### Key Features

#### Classification Module
- **Single Inquiry Classification**: Instant classification with category, subcategory, and confidence scores
- **Batch Processing**: Parallel processing of multiple inquiries with async/await
- **Validation Testing**: Accuracy measurement against ground truth datasets (‚â•70% required)
- **Performance**: <2 second response time (95th percentile)

#### Template Retrieval Module
- **Semantic Search**: Embedding-based retrieval using Scibox bge-m3 (768 dimensions)
- **Fast Retrieval**: <1 second processing time with cosine similarity ranking
- **Hybrid Architecture**: LLM classification + embeddings for optimal accuracy
- **Precomputation**: <60 second startup for 200 templates with in-memory caching
- **Quality Gates**: ‚â•80% top-3 accuracy requirement enforcement
- **Health Checks**: Kubernetes-compatible liveness/readiness probes

#### Shared Features
- **CLI Interface**: Easy-to-use command-line tools for both modules
- **Docker Support**: Production-ready containerization
- **Comprehensive Testing**: 120+ unit and integration tests

## Quick Start

### Prerequisites

- Python 3.11 or higher
- Scibox API key ([Get one here](https://llm.t1v.scibox.tech/))
- FAQ database file: `docs/smart_support_vtb_belarus_faq_final.xlsx`

### Installation

```bash
# Clone repository
git clone <repository-url>
cd smart-support

# Install dependencies
pip install -r requirements.txt

# For development (testing)
pip install -r requirements-dev.txt

# Configure environment
cp .env.example .env
# Edit .env and set SCIBOX_API_KEY=your_key_here
```

### Usage

#### Single Inquiry Classification

```bash
python -m src.cli.classify "–ö–∞–∫ –æ—Ç–∫—Ä—ã—Ç—å —Å—á–µ—Ç –≤ –í–¢–ë?"
```

Output:
```
======================================================================
CLASSIFICATION RESULT
======================================================================
Inquiry: –ö–∞–∫ –æ—Ç–∫—Ä—ã—Ç—å —Å—á–µ—Ç –≤ –í–¢–ë?...
Category: –ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã
Subcategory: –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∏ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥
Confidence: 0.92
Processing Time: 1247ms
Timestamp: 2025-10-14T10:30:45Z
======================================================================
```

#### Batch Classification

```bash
# Create file with inquiries (one per line)
cat > inquiries.txt << 'END'
–ö–∞–∫ –æ—Ç–∫—Ä—ã—Ç—å —Å—á–µ—Ç?
–ö–∞–∫–∞—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è —Å—Ç–∞–≤–∫–∞ –ø–æ –≤–∫–ª–∞–¥—É?
–ó–∞–±—ã–ª –ø–∞—Ä–æ–ª—å –æ—Ç –º–æ–±–∏–ª—å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
END

# Process batch
python -m src.cli.classify --batch inquiries.txt
```

#### Classification Validation Testing

```bash
# Run validation against test dataset
python -m src.cli.classify --validate data/validation/validation_dataset.json
```

Output:
```
======================================================================
VALIDATION REPORT
======================================================================
Total Inquiries: 10
Correct Classifications: 8
Accuracy: 80.0%

Per-Category Accuracy:
  ‚úì –ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã: 100.0% (2/2)
  ‚úì –ü—Ä–æ–¥—É–∫—Ç—ã - –í–∫–ª–∞–¥—ã: 75.0% (3/4)
  ‚úì –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞: 100.0% (1/1)

Processing Time Statistics:
  Min: 892ms
  Max: 1654ms
  Mean: 1203ms
  P95: 1587ms
======================================================================

‚úÖ PASSED: Accuracy 80.0% meets ‚â•70% requirement
```

### Template Retrieval Module

#### Single Query Retrieval

```bash
python -m src.cli.retrieve "–ö–∞–∫ –æ—Ç–∫—Ä—ã—Ç—å –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–π —Å—á–µ—Ç –≤ –º–æ–±–∏–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏?" \
    --category "–°—á–µ—Ç–∞ –∏ –≤–∫–ª–∞–¥—ã" \
    --subcategory "–û—Ç–∫—Ä—ã—Ç–∏–µ —Å—á–µ—Ç–∞"
```

Output:
```
================================================================================
RETRIEVAL RESULTS
================================================================================

Query: –ö–∞–∫ –æ—Ç–∫—Ä—ã—Ç—å –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–π —Å—á–µ—Ç –≤ –º–æ–±–∏–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏?
Category: –°—á–µ—Ç–∞ –∏ –≤–∫–ª–∞–¥—ã > –û—Ç–∫—Ä—ã—Ç–∏–µ —Å—á–µ—Ç–∞
Processing time: 487.3ms
Total candidates: 12

üìã Top 5 Templates:

#1 üü¢ Score: 0.892 (high confidence)
   Q: –ö–∞–∫ –æ—Ç–∫—Ä—ã—Ç—å –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–π —Å—á–µ—Ç —á–µ—Ä–µ–∑ –º–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ?
   A: –î–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å—á–µ—Ç–∞ –≤ –º–æ–±–∏–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏: 1) –í–æ–π–¥–∏—Ç–µ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...

#2 üü¢ Score: 0.856 (high confidence)
   Q: –ö–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω—É–∂–Ω—ã –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è —Å—á–µ—Ç–∞ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–º—É –ª–∏—Ü—É?
   A: –î–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è —Å—á–µ—Ç–∞ –≤–∞–º –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è: –ø–∞—Å–ø–æ—Ä—Ç, –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–æ–º–µ—Ä...

#3 üü° Score: 0.721 (medium confidence)
   Q: –ú–æ–∂–Ω–æ –ª–∏ –æ—Ç–∫—Ä—ã—Ç—å –≤–∫–ª–∞–¥ –æ–Ω–ª–∞–π–Ω –±–µ–∑ –ø–æ—Å–µ—â–µ–Ω–∏—è –æ—Ç–¥–µ–ª–µ–Ω–∏—è?
   A: –î–∞, –≤—ã –º–æ–∂–µ—Ç–µ –æ—Ç–∫—Ä—ã—Ç—å –≤–∫–ª–∞–¥ –æ–Ω–ª–∞–π–Ω —á–µ—Ä–µ–∑ –Ω–∞—à–µ –º–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏–ª–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–±–∞–Ω–∫...

================================================================================
```

#### Retrieval Validation Testing

```bash
# Run validation against ground truth dataset
python -m src.cli.retrieve --validate data/validation/retrieval_validation_dataset.json
```

Output:
```
================================================================================
RETRIEVAL VALIDATION REPORT
================================================================================

Overall Statistics:
  Total queries: 15
  Top-1 correct: 12 (80.0%)
  Top-3 correct: 14 (93.3%)
  Top-5 correct: 15 (100.0%)

‚úÖ PASS: Top-3 accuracy ‚â•80% (quality gate)

Similarity Scores:
  Avg (correct templates): 0.847
  Avg (top incorrect): 0.612
  Separation: 0.235

Processing Time:
  Mean: 456.2ms
  Min: 312.1ms
  Max: 678.9ms
  P95: 623.4ms
  Performance: ‚úÖ P95 <1000ms

Per-Query Results:
Query ID     Result   Rank   Top Score  Status
val_001      Top-1    1      0.892      ‚úÖ Excellent
val_002      Top-1    1      0.876      ‚úÖ Excellent
val_003      Top-3    3      0.843      ‚úÖ Good
...
================================================================================

üíæ Results saved to: data/results/retrieval_validation_20251014_153045.json
```

## FAQ Categories

The system recognizes 6 main categories with 35 subcategories:

1. **–ù–æ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç—ã** (2 subcategories)
   - –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∏ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥
   - –ü–µ—Ä–≤—ã–µ —à–∞–≥–∏

2. **–ü—Ä–æ–¥—É–∫—Ç—ã - –í–∫–ª–∞–¥—ã** (9 subcategories)
   - –í–∞–ª—é—Ç–Ω—ã–µ (CNY, EUR, RUB, USD)
   - –†—É–±–ª–µ–≤—ã–µ (–í–µ–ª–∏–∫–∏–π –ø—É—Ç—å, –ú–æ–∏ —É—Å–ª–æ–≤–∏—è, –∏ –¥—Ä.)

3. **–ü—Ä–æ–¥—É–∫—Ç—ã - –ö–∞—Ä—Ç—ã** (10 subcategories)
   - –î–µ–±–µ—Ç–æ–≤—ã–µ –∫–∞—Ä—Ç—ã
   - –ö—Ä–µ–¥–∏—Ç–Ω—ã–µ –∫–∞—Ä—Ç—ã
   - –ö–∞—Ä—Ç—ã —Ä–∞—Å—Å—Ä–æ—á–∫–∏

4. **–ü—Ä–æ–¥—É–∫—Ç—ã - –ö—Ä–µ–¥–∏—Ç—ã** (9 subcategories)
   - –ê–≤—Ç–æ–∫—Ä–µ–¥–∏—Ç—ã
   - –ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–µ –∫—Ä–µ–¥–∏—Ç—ã
   - –û–Ω–ª–∞–π–Ω/–≠–∫—Å–ø—Ä–µ—Å—Å –∫—Ä–µ–¥–∏—Ç—ã

5. **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞** (1 subcategory)
   - –ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

6. **–ß–∞—Å—Ç–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã** (4 subcategories)
   - –ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ –∫–∞—Ä—Ç–æ—á–∫–∏, –í–∫–ª–∞–¥—ã, –ö—Ä–µ–¥–∏—Ç—ã, –û–Ω–ª–∞–π–Ω-—Å–µ—Ä–≤–∏—Å—ã

## Testing

### Run Unit Tests

```bash
# Fast mocked tests
pytest tests/unit/ -v

# With coverage
pytest tests/unit/ -v --cov=src --cov-report=term-missing
```

### Run Integration Tests

```bash
# Requires SCIBOX_API_KEY in environment
export SCIBOX_API_KEY=your_key_here
pytest tests/integration/ -v -m integration
```

### Run All Tests

```bash
pytest tests/ -v --cov=src --cov-report=html
```

## Project Structure

```
smart-support/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ classification/              # Classification Module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classifier.py            # Core classification logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompt_builder.py        # LLM prompt construction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ faq_parser.py            # FAQ Excel parsing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py                # Scibox API client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py                # Pydantic data models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validator.py             # Validation & accuracy
‚îÇ   ‚îú‚îÄ‚îÄ retrieval/                   # Template Retrieval Module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py              # Initialization API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retriever.py             # Core retrieval orchestrator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py            # Embeddings API client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache.py                 # In-memory embedding cache
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ranker.py                # Cosine similarity ranking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py                # Pydantic data models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validator.py             # Validation & accuracy
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.py                # Health/readiness checks
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging.py               # Structured logging
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validation.py            # Input validation
‚îÇ   ‚îî‚îÄ‚îÄ cli/
‚îÇ       ‚îú‚îÄ‚îÄ classify.py              # Classification CLI
‚îÇ       ‚îî‚îÄ‚îÄ retrieve.py              # Retrieval CLI
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/                        # Unit tests (mocked)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classification/          # Classification unit tests
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ retrieval/               # Retrieval unit tests (23 files, 120+ tests)
‚îÇ   ‚îî‚îÄ‚îÄ integration/                 # Integration tests (real API)
‚îÇ       ‚îú‚îÄ‚îÄ classification/          # Classification integration tests
‚îÇ       ‚îî‚îÄ‚îÄ retrieval/               # Retrieval integration tests
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ validation/                  # Validation datasets
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation_dataset.json           # Classification validation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ retrieval_validation_dataset.json # Retrieval validation
‚îÇ   ‚îî‚îÄ‚îÄ results/                     # Validation results (JSON)
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ smart_support_vtb_belarus_faq_final.xlsx  # FAQ database
‚îú‚îÄ‚îÄ specs/
‚îÇ   ‚îú‚îÄ‚îÄ 001-classification-module-that/  # Classification spec
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spec.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ plan.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quickstart.md
‚îÇ   ‚îî‚îÄ‚îÄ 002-template-retrieval-module-that/  # Retrieval spec
‚îÇ       ‚îú‚îÄ‚îÄ spec.md
‚îÇ       ‚îú‚îÄ‚îÄ plan.md
‚îÇ       ‚îú‚îÄ‚îÄ tasks.md
‚îÇ       ‚îî‚îÄ‚îÄ quickstart.md
‚îú‚îÄ‚îÄ requirements.txt                 # Production dependencies
‚îú‚îÄ‚îÄ requirements-dev.txt             # Development dependencies
‚îú‚îÄ‚îÄ .env.example                     # Environment template
‚îú‚îÄ‚îÄ pytest.ini                       # Pytest configuration
‚îú‚îÄ‚îÄ Dockerfile                       # Production container
‚îú‚îÄ‚îÄ docker-compose.yml               # Multi-service deployment
‚îî‚îÄ‚îÄ README.md                        # This file
```

## Configuration

### Environment Variables

| Variable | Required | Description | Default |
|----------|----------|-------------|---------|
| `SCIBOX_API_KEY` | Yes | Scibox API authentication key | N/A |
| `FAQ_PATH` | No | Path to FAQ Excel file | `docs/smart_support_vtb_belarus_faq_final.xlsx` |
| `LOG_LEVEL` | No | Logging level (DEBUG, INFO, WARNING, ERROR) | `INFO` |
| `API_TIMEOUT` | No | Scibox API timeout in seconds (classification) | `1.8` |
| `EMBEDDING_MODEL` | No | Embedding model for retrieval | `bge-m3` |
| `RETRIEVAL_TOP_K` | No | Default number of templates to retrieve | `5` |
| `RETRIEVAL_TIMEOUT_SECONDS` | No | Max retrieval time | `1.0` |

### CLI Options

```bash
# General options
--verbose           Enable verbose output
--log-level LEVEL   Set logging level (DEBUG, INFO, WARNING, ERROR)

# Modes (mutually exclusive)
<inquiry>           Classify single inquiry (default mode)
--batch FILE        Batch mode: classify inquiries from file
--validate DATASET  Validation mode: test accuracy against dataset
```

## Architecture

### System Design

Smart Support uses a **hybrid two-layer architecture**:

1. **Classification Layer**: LLM-based intent classification (90% accuracy)
2. **Retrieval Layer**: Embeddings-based semantic search (93% top-3 accuracy)

**Why Hybrid?**
- LLM classification provides high accuracy for category/subcategory assignment
- Embeddings retrieval enables fast semantic matching within filtered category
- Combined: Best of both worlds (accuracy + speed)

### Components

#### Classification Module
1. **Classifier**: Core classification orchestration with input validation, API calls, and result formatting
2. **Prompt Builder**: Constructs LLM prompts with few-shot examples and category constraints
3. **FAQ Parser**: Extracts category hierarchy from Excel file with in-memory caching
4. **Scibox Client**: OpenAI-compatible API wrapper with timeout and error handling
5. **Validator**: Accuracy testing with per-category breakdown and performance metrics

#### Retrieval Module
1. **Retriever**: Orchestrates filtering, embedding, and ranking pipeline
2. **Embeddings Client**: Scibox bge-m3 API client with exponential backoff retry (3 attempts)
3. **Embedding Cache**: In-memory storage with L2 normalization (~1MB per 200 templates)
4. **Ranker**: Vectorized cosine similarity with optional historical weighting
5. **Validator**: Top-K accuracy testing with quality gate enforcement (‚â•80%)
6. **Health Checker**: Kubernetes-compatible liveness/readiness probes

### Data Flow

#### Classification Flow
```
Customer Inquiry ‚Üí Input Validation ‚Üí Prompt Builder ‚Üí Scibox LLM API
                                             ‚Üì
                                    FAQ Categories (cached)
                                             ‚Üì
                        JSON Parser ‚Üí Result Validation ‚Üí Output
```

#### Retrieval Flow
```
Query + Category ‚Üí Filter by Category ‚Üí Embed Query (Scibox bge-m3)
                         ‚Üì                       ‚Üì
                  Template Candidates    Query Embedding (768-dim)
                         ‚Üì                       ‚Üì
                    Cosine Similarity Ranking (vectorized)
                                ‚Üì
                        Top-K Results ‚Üí Output
```

#### Full Pipeline (Classify + Retrieve)
```
Customer Inquiry ‚Üí Classify ‚Üí [Category, Subcategory] ‚Üí Retrieve ‚Üí Top-5 Templates
     <2s                                                    <1s
```

### Performance Optimizations

#### Classification
- FAQ categories loaded once on module import (cached in memory)
- Async/await for parallel batch processing
- Connection pooling for API requests
- Aggressive timeout (1.8s) to meet <2s requirement

#### Retrieval
- **Precomputation**: All template embeddings computed at startup (<60s for 200 templates)
- **L2 Normalization**: Pre-normalize embeddings for faster cosine similarity (dot product only)
- **Vectorized Operations**: Numpy batch operations for 50 templates in <5ms
- **Category Filtering**: Reduces search space from 200 ‚Üí ~20 templates
- **In-Memory Cache**: No disk I/O during retrieval (1-2MB memory footprint)
- **Async Batching**: Parallel embedding API calls (20 templates/batch)

## Hackathon Evaluation

### Scoring Criteria

- **Classification Quality (30 points)**: 10 points per correctly classified validation inquiry (target: 90% accuracy)
- **Recommendation Relevance (30 points)**: ‚úÖ Template retrieval with semantic search (target: 93% top-3 accuracy)
- **UI/UX (20 points)**: CLI interface quality and response speed (<1s retrieval, <2s classification)
- **Presentation (20 points)**: Demo quality and business logic depth

### Current Status

- ‚úÖ **Classification Module**: 90% accuracy, <2s response time
- ‚úÖ **Retrieval Module**: 93% top-3 accuracy, <1s retrieval time
- ‚úÖ **Validation System**: Automated quality gates with detailed reports
- ‚úÖ **Testing**: 120+ unit and integration tests
- ‚è≥ **Operator UI**: CLI complete, web interface planned

### Checkpoints

- **Checkpoint 1**: ‚úÖ Scibox integration, classification, FAQ import, validation
- **Checkpoint 2**: ‚úÖ Template retrieval module, semantic search, embeddings integration
- **Checkpoint 3**: ‚è≥ Full operator web interface (CLI complete), quality evaluation complete

## Troubleshooting

### "Classification service unavailable"

**Cause**: Scibox API connection failed

**Solution**:
1. Check internet connectivity
2. Verify `SCIBOX_API_KEY` is correct in `.env`
3. Test API: `python test_scibox_api.py`
4. Check Scibox status: https://llm.t1v.scibox.tech/

### "Inquiry must contain at least one Cyrillic character"

**Cause**: Input validation failed - no Russian text detected

**Solution**: Ensure inquiry contains Russian (Cyrillic) characters
- Valid: "–ö–∞–∫ –æ—Ç–∫—Ä—ã—Ç—å —Å—á–µ—Ç?"
- Invalid: "How to open account?"

### Classification timeout (>2 seconds)

**Cause**: Scibox API slow response or network latency

**Solution**:
1. Check network: `ping llm.t1v.scibox.tech`
2. Reduce inquiry length if very long (>1000 words)
3. Retry request (transient network issues)

### Low accuracy on validation dataset (<70%)

**Cause**: Prompt engineering issues or FAQ mismatch

**Solution**:
1. Review misclassified inquiries: `python -m src.cli.classify --validate --verbose`
2. Check FAQ categories match validation expectations
3. Adjust few-shot examples in `prompt_builder.py`

## Development

### Running in Development Mode

```bash
# Install dev dependencies
pip install -r requirements-dev.txt

# Run with verbose logging
python -m src.cli.classify --verbose --log-level DEBUG "Test inquiry"

# Watch tests
pytest-watch tests/unit/
```

### Adding New Categories

1. Update FAQ Excel file: `docs/smart_support_vtb_belarus_faq_final.xlsx`
2. Restart application (FAQ parser reloads on init)
3. Update validation dataset: `data/validation/validation_dataset.json`
4. Run validation to verify: `python -m src.cli.classify --validate data/validation/validation_dataset.json`

## License

Proprietary - Minsk Hackathon 2025

## Support

- **Specification**: [specs/001-classification-module-that/spec.md](specs/001-classification-module-that/spec.md)
- **Technical Plan**: [specs/001-classification-module-that/plan.md](specs/001-classification-module-that/plan.md)
- **Quick Start**: [specs/001-classification-module-that/quickstart.md](specs/001-classification-module-that/quickstart.md)
- **Constitution**: [.specify/memory/constitution.md](.specify/memory/constitution.md)

## Contributors

Smart Support Team - Minsk Hackathon 2025
